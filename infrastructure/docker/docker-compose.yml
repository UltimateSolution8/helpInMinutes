version: '3.8'

# ============================================
# HelpInMinutes Production Docker Compose
# ============================================

services:
  # ============================================
  # PostgreSQL with PostGIS
  # ============================================
  postgres:
    image: postgis/postgis:15-3.4
    container_name: him-postgres
    hostname: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_backups:/backups
      - ./init-scripts:/docker-entrypoint-initdb.d
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    deploy:
      resources:
        limits:
          cpus: '${POSTGRES_CPU_LIMIT:-2}'
          memory: ${POSTGRES_MEMORY_LIMIT:-4G}
        reservations:
          cpus: '${POSTGRES_CPU_RESERVATION:-1}'
          memory: ${POSTGRES_MEMORY_RESERVATION:-2G}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    restart: unless-stopped
      condition: on-failure
      delay: 5s
      max_attempts: 5
      window: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    networks:
      - frontend
      - backend
    command: |
      postgres
      -c max_connections=200
      -c shared_buffers=1GB
      -c effective_cache_size=3GB
      -c work_mem=256MB
      -c maintenance_work_mem=512MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=64MB
      -c max_wal_size=2GB
      -c min_wal_size=1GB
      -c log_connections=on
      -c log_disconnections=on
      -c log_duration=on
      -c log_lock_waits=on

  # ============================================
  # Redis with persistence
  # ============================================
  redis:
    image: redis:7-alpine
    container_name: him-redis
    hostname: redis
    command: |
      redis-server
      --appendonly yes
      --appendfsync everysec
      --no-appendfsync-on-rewrite no
      --auto-aof-rewrite-percentage 100
      --auto-aof-rewrite-min-size 64mb
      --maxmemory ${REDIS_MAX_MEMORY:-1gb}
      --maxmemory-policy allkeys-lru
      --timeout 300
      --tcp-backlog 511
      --tcp-keepalive 300
      --loglevel notice
    volumes:
      - redis_data:/data
      - redis_conf:/usr/local/etc/redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    deploy:
      resources:
        limits:
          cpus: '${REDIS_CPU_LIMIT:-1}'
          memory: ${REDIS_MEMORY_LIMIT:-2G}
        reservations:
          cpus: '${REDIS_CPU_RESERVATION:-0.5}'
          memory: ${REDIS_MEMORY_RESERVATION:-1G}
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s
    restart: unless-stopped
      condition: on-failure
      delay: 5s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
    networks:
      - backend
    profiles:
      - infrastructure

  # ============================================
  # RabbitMQ with clustering and management
  # ============================================
  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: him-rabbitmq
    hostname: rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_DEFAULT_VHOST: /helpinminutes
      RABBITMQ_ERLANG_COOKIE: ${RABBITMQ_ERLANG_COOKIE:-helpinminutes-erlang-cookie}
      RABBITMQ_NODENAME: rabbit@rabbitmq
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - rabbitmq_logs:/var/log/rabbitmq
      - ./rabbitmq/definitions.json:/etc/rabbitmq/definitions.json:ro
      - ./rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
    ports:
      - "${RABBITMQ_PORT:-5672}:5672"
      - "${RABBITMQ_MANAGEMENT_PORT:-15672}:15672"
      - "${RABBITMQ_STOMP_PORT:-61613}:61613"
    deploy:
      resources:
        limits:
          cpus: '${RABBITMQ_CPU_LIMIT:-1}'
          memory: ${RABBITMQ_MEMORY_LIMIT:-2G}
        reservations:
          cpus: '${RABBITMQ_CPU_RESERVATION:-0.5}'
          memory: ${RABBITMQ_MEMORY_RESERVATION:-1G}
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "check_port_connectivity"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 30s
    restart: unless-stopped
      condition: on-failure
      delay: 5s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    networks:
      - backend
    profiles:
      - infrastructure

  # ============================================
  # MinIO for object storage
  # ============================================
  minio:
    image: minio/minio:RELEASE.2024-01-01T00-00-00Z
    container_name: him-minio
    hostname: minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_PROMETHEUS_AUTH_TYPE: public
      MINIO_BROWSER_REDIRECT_URL: ${MINIO_CONSOLE_URL:-http://localhost:9001}
    volumes:
      - minio_data:/data
      - minio_config:/root/.minio
    ports:
      - "${MINIO_API_PORT:-9000}:9000"
      - "${MINIO_CONSOLE_PORT:-9001}:9001"
    deploy:
      resources:
        limits:
          cpus: '${MINIO_CPU_LIMIT:-1}'
          memory: ${MINIO_MEMORY_LIMIT:-2G}
        reservations:
          cpus: '${MINIO_CPU_RESERVATION:-0.5}'
          memory: ${MINIO_MEMORY_RESERVATION:-1G}
    command: server /data --console-address ":9001" --api-address ":9000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 10
      start_period: 30s
    restart: unless-stopped
      condition: on-failure
      delay: 5s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
    networks:
      - backend
      - storage
    profiles:
      - infrastructure

  # ============================================
  # MinIO Client (mc) for bucket setup
  # ============================================
  minio-setup:
    image: minio/mc:RELEASE.2024-01-01T00-00-00Z
    container_name: him-minio-setup
    depends_on:
      minio:
        condition: service_healthy
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - ./minio/setup-buckets.sh:/setup-buckets.sh:ro
    entrypoint: ["/bin/sh", "/setup-buckets.sh"]
    profiles:
      - infrastructure

  # ============================================
  # Identity Service (Java/Spring Boot)
  # ============================================
  identity-service:
    image: ${DOCKER_REGISTRY:-docker.io}/helpinminutes/identity-service:${IMAGE_TAG:-latest}
    container_name: him-identity-service
    hostname: identity-service
    build:
      context: ../../services/identity-service
      dockerfile: Dockerfile
      target: production
    environment:
      SPRING_PROFILES_ACTIVE: docker
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB}
      SPRING_DATASOURCE_USERNAME: ${POSTGRES_USER}
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD}
      SPRING_REDIS_HOST: redis
      SPRING_REDIS_PORT: 6379
      SPRING_REDIS_PASSWORD: ${REDIS_PASSWORD}
      SPRING_RABBITMQ_HOST: rabbitmq
      SPRING_RABBITMQ_PORT: 5672
      SPRING_RABBITMQ_USERNAME: ${RABBITMQ_USER}
      SPRING_RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
      JWT_SECRET: ${JWT_SECRET}
      JWT_EXPIRATION: ${JWT_EXPIRATION}
      JWT_REFRESH_EXPIRATION: ${JWT_REFRESH_EXPIRATION}
      JAEGER_SERVICE_NAME: identity-service
      JAEGER_AGENT_HOST: jaeger
      JAEGER_AGENT_PORT: 6831
      LOGGING_LEVEL_ROOT: INFO
      SERVER_PORT: 8081
    ports:
      - "${IDENTITY_SERVICE_PORT:-8081}:8081"
    deploy:
      resources:
        limits:
          cpus: '${IDENTITY_CPU_LIMIT:-1}'
          memory: ${IDENTITY_MEMORY_LIMIT:-1G}
        reservations:
          cpus: '${IDENTITY_CPU_RESERVATION:-0.5}'
          memory: ${IDENTITY_MEMORY_RESERVATION:-512M}
      replicas: ${IDENTITY_REPLICAS:-1}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s
    restart: unless-stopped
      condition: on-failure
      delay: 10s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    networks:
      - frontend
      - backend
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  # ============================================
  # Task Service (Java/Spring Boot)
  # ============================================
  task-service:
    image: ${DOCKER_REGISTRY:-docker.io}/helpinminutes/task-service:${IMAGE_TAG:-latest}
    container_name: him-task-service
    hostname: task-service
    build:
      context: ../../services/task-service
      dockerfile: Dockerfile
      target: production
    environment:
      SPRING_PROFILES_ACTIVE: docker
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB}
      SPRING_DATASOURCE_USERNAME: ${POSTGRES_USER}
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD}
      SPRING_REDIS_HOST: redis
      SPRING_REDIS_PORT: 6379
      SPRING_REDIS_PASSWORD: ${REDIS_PASSWORD}
      SPRING_RABBITMQ_HOST: rabbitmq
      SPRING_RABBITMQ_PORT: 5672
      SPRING_RABBITMQ_USERNAME: ${RABBITMQ_USER}
      SPRING_RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
      JAEGER_SERVICE_NAME: task-service
      JAEGER_AGENT_HOST: jaeger
      JAEGER_AGENT_PORT: 6831
      LOGGING_LEVEL_ROOT: INFO
      SERVER_PORT: 8082
    ports:
      - "${TASK_SERVICE_PORT:-8082}:8082"
    deploy:
      resources:
        limits:
          cpus: '${TASK_CPU_LIMIT:-1}'
          memory: ${TASK_MEMORY_LIMIT:-1G}
        reservations:
          cpus: '${TASK_CPU_RESERVATION:-0.5}'
          memory: ${TASK_MEMORY_RESERVATION:-512M}
      replicas: ${TASK_REPLICAS:-1}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s
    restart: unless-stopped
      condition: on-failure
      delay: 10s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    networks:
      - frontend
      - backend
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  # ============================================
  # Matching Service (Java/Spring Boot)
  # ============================================
  matching-service:
    image: ${DOCKER_REGISTRY:-docker.io}/helpinminutes/matching-service:${IMAGE_TAG:-latest}
    container_name: him-matching-service
    hostname: matching-service
    build:
      context: ../../services/matching-service
      dockerfile: Dockerfile
      target: production
    environment:
      SPRING_PROFILES_ACTIVE: docker
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB}
      SPRING_DATASOURCE_USERNAME: ${POSTGRES_USER}
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD}
      SPRING_REDIS_HOST: redis
      SPRING_REDIS_PORT: 6379
      SPRING_REDIS_PASSWORD: ${REDIS_PASSWORD}
      SPRING_RABBITMQ_HOST: rabbitmq
      SPRING_RABBITMQ_PORT: 5672
      SPRING_RABBITMQ_USERNAME: ${RABBITMQ_USER}
      SPRING_RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
      JAEGER_SERVICE_NAME: matching-service
      JAEGER_AGENT_HOST: jaeger
      JAEGER_AGENT_PORT: 6831
      LOGGING_LEVEL_ROOT: INFO
      SERVER_PORT: 8083
    ports:
      - "${MATCHING_SERVICE_PORT:-8083}:8083"
    deploy:
      resources:
        limits:
          cpus: '${MATCHING_CPU_LIMIT:-1}'
          memory: ${MATCHING_MEMORY_LIMIT:-1G}
        reservations:
          cpus: '${MATCHING_CPU_RESERVATION:-0.5}'
          memory: ${MATCHING_MEMORY_RESERVATION:-512M}
      replicas: ${MATCHING_REPLICAS:-1}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s
    restart: unless-stopped
      condition: on-failure
      delay: 10s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    networks:
      - frontend
      - backend
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  # ============================================
  # Payment Service (Java/Spring Boot)
  # ============================================
  payment-service:
    image: ${DOCKER_REGISTRY:-docker.io}/helpinminutes/payment-service:${IMAGE_TAG:-latest}
    container_name: him-payment-service
    hostname: payment-service
    build:
      context: ../../services/payment-service
      dockerfile: Dockerfile
      target: production
    environment:
      SPRING_PROFILES_ACTIVE: docker
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB}
      SPRING_DATASOURCE_USERNAME: ${POSTGRES_USER}
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD}
      SPRING_REDIS_HOST: redis
      SPRING_REDIS_PORT: 6379
      SPRING_REDIS_PASSWORD: ${REDIS_PASSWORD}
      SPRING_RABBITMQ_HOST: rabbitmq
      SPRING_RABBITMQ_PORT: 5672
      SPRING_RABBITMQ_USERNAME: ${RABBITMQ_USER}
      SPRING_RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
      RAZORPAY_KEY_ID: ${RAZORPAY_KEY_ID}
      RAZORPAY_KEY_SECRET: ${RAZORPAY_KEY_SECRET}
      RAZORPAY_WEBHOOK_SECRET: ${RAZORPAY_WEBHOOK_SECRET}
      JAEGER_SERVICE_NAME: payment-service
      JAEGER_AGENT_HOST: jaeger
      JAEGER_AGENT_PORT: 6831
      LOGGING_LEVEL_ROOT: INFO
      SERVER_PORT: 8084
    ports:
      - "${PAYMENT_SERVICE_PORT:-8084}:8084"
    deploy:
      resources:
        limits:
          cpus: '${PAYMENT_CPU_LIMIT:-1}'
          memory: ${PAYMENT_MEMORY_LIMIT:-1G}
        reservations:
          cpus: '${PAYMENT_CPU_RESERVATION:-0.5}'
          memory: ${PAYMENT_MEMORY_RESERVATION:-512M}
      replicas: ${PAYMENT_REPLICAS:-1}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8084/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s
    restart: unless-stopped
      condition: on-failure
      delay: 10s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    networks:
      - frontend
      - backend
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  # ============================================
  # Realtime Service (Node.js/PM2)
  # ============================================
  realtime-service:
    image: ${DOCKER_REGISTRY:-docker.io}/helpinminutes/realtime-service:${IMAGE_TAG:-latest}
    container_name: him-realtime-service
    hostname: realtime-service
    build:
      context: ../../services/realtime-service
      dockerfile: Dockerfile
      target: production
    environment:
      NODE_ENV: production
      PORT: 8085
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      RABBITMQ_USER: ${RABBITMQ_USER}
      RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
      JWT_SECRET: ${JWT_SECRET}
      JAEGER_SERVICE_NAME: realtime-service
      JAEGER_AGENT_HOST: jaeger
      JAEGER_AGENT_PORT: 6831
    ports:
      - "${REALTIME_SERVICE_PORT:-8085}:8085"
    deploy:
      resources:
        limits:
          cpus: '${REALTIME_CPU_LIMIT:-1}'
          memory: ${REALTIME_MEMORY_LIMIT:-1G}
        reservations:
          cpus: '${REALTIME_CPU_RESERVATION:-0.5}'
          memory: ${REALTIME_MEMORY_RESERVATION:-512M}
      replicas: ${REALTIME_REPLICAS:-1}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8085/health"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 30s
    restart: unless-stopped
      condition: on-failure
      delay: 10s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    networks:
      - frontend
      - backend
    depends_on:
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  # ============================================
  # Admin Portal (Node.js/Next.js)
  # ============================================
  admin-portal:
    image: ${DOCKER_REGISTRY:-docker.io}/helpinminutes/admin-portal:${IMAGE_TAG:-latest}
    container_name: him-admin-portal
    hostname: admin-portal
    build:
      context: ../../admin-portal
      dockerfile: Dockerfile
      target: production
    environment:
      NODE_ENV: production
      NEXT_PUBLIC_API_URL: ${API_URL:-http://nginx:80/api}
      NEXT_PUBLIC_WS_URL: ${WS_URL:-ws://nginx:80/ws}
      JWT_SECRET: ${JWT_SECRET}
    ports:
      - "${ADMIN_PORTAL_PORT:-3000}:3000"
    deploy:
      resources:
        limits:
          cpus: '${ADMIN_CPU_LIMIT:-1}'
          memory: ${ADMIN_MEMORY_LIMIT:-1G}
        reservations:
          cpus: '${ADMIN_CPU_RESERVATION:-0.5}'
          memory: ${ADMIN_MEMORY_RESERVATION:-512M}
      replicas: ${ADMIN_REPLICAS:-1}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 30s
    restart: unless-stopped
      condition: on-failure
      delay: 10s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
    networks:
      - frontend
    depends_on:
      - identity-service
      - task-service

  # ============================================
  # Nginx Reverse Proxy
  # ============================================
  nginx:
    image: nginx:1.25-alpine
    container_name: him-nginx
    hostname: nginx
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - admin_portal_build:/usr/share/nginx/html:ro
    ports:
      - "${HTTP_PORT:-80}:80"
      - "${HTTPS_PORT:-443}:443"
    deploy:
      resources:
        limits:
          cpus: '${NGINX_CPU_LIMIT:-1}'
          memory: ${NGINX_MEMORY_LIMIT:-512M}
        reservations:
          cpus: '${NGINX_CPU_RESERVATION:-0.25}'
          memory: ${NGINX_MEMORY_RESERVATION:-256M}
      replicas: ${NGINX_REPLICAS:-1}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 10s
    restart: unless-stopped
      condition: on-failure
      delay: 5s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    networks:
      - frontend
    depends_on:
      - identity-service
      - task-service
      - matching-service
      - payment-service
      - realtime-service
      - admin-portal

  # ============================================
  # Prometheus Monitoring
  # ============================================
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: him-prometheus
    hostname: prometheus
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/rules:/etc/prometheus/rules:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
      - '--query.max-concurrency=10'
      - '--query.timeout=2m'
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    deploy:
      resources:
        limits:
          cpus: '${PROMETHEUS_CPU_LIMIT:-1}'
          memory: ${PROMETHEUS_MEMORY_LIMIT:-2G}
        reservations:
          cpus: '${PROMETHEUS_CPU_RESERVATION:-0.5}'
          memory: ${PROMETHEUS_MEMORY_RESERVATION:-1G}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 10
    restart: unless-stopped
      condition: on-failure
      delay: 5s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
    networks:
      - monitoring
    profiles:
      - monitoring

  # ============================================
  # Grafana Dashboard
  # ============================================
  grafana:
    image: grafana/grafana:10.2.0
    container_name: him-grafana
    hostname: grafana
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin123}
      GF_USERS_ALLOW_SIGN_UP: false
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    deploy:
      resources:
        limits:
          cpus: '${GRAFANA_CPU_LIMIT:-1}'
          memory: ${GRAFANA_MEMORY_LIMIT:-1G}
        reservations:
          cpus: '${GRAFANA_CPU_RESERVATION:-0.5}'
          memory: ${GRAFANA_MEMORY_RESERVATION:-512M}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 10
    restart: unless-stopped
      condition: on-failure
      delay: 5s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
    networks:
      - monitoring
    depends_on:
      - prometheus
    profiles:
      - monitoring

  # ============================================
  # Jaeger Tracing
  # ============================================
  jaeger:
    image: jaegertracing/all-in-one:1.52
    container_name: him-jaeger
    hostname: jaeger
    environment:
      COLLECTOR_OTLP_ENABLED: true
      QUERY_BASE_PATH: /jaeger
    volumes:
      - jaeger_data:/tmp/jaeger
    ports:
      - "${JAEGER_COLLECTOR_PORT:-14268}:14268"
      - "${JAEGER_QUERY_PORT:-16686}:16686"
      - "${JAEGER_AGENT_PORT:-6831}:6831/udp"
      - "${JAEGER_ZIPKIN_PORT:-9411}:9411"
    deploy:
      resources:
        limits:
          cpus: '${JAEGER_CPU_LIMIT:-1}'
          memory: ${JAEGER_MEMORY_LIMIT:-2G}
        reservations:
          cpus: '${JAEGER_CPU_RESERVATION:-0.5}'
          memory: ${JAEGER_MEMORY_RESERVATION:-1G}
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:16686/"]
      interval: 30s
      timeout: 10s
      retries: 10
    restart: unless-stopped
      condition: on-failure
      delay: 5s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
    networks:
      - monitoring
    profiles:
      - monitoring

  # ============================================
  # Alertmanager
  # ============================================
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: him-alertmanager
    hostname: alertmanager
    volumes:
      - ./monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--cluster.advertise-address=0.0.0.0:9093'
    ports:
      - "${ALERTMANAGER_PORT:-9093}:9093"
    deploy:
      resources:
        limits:
          cpus: '${ALERTMANAGER_CPU_LIMIT:-0.5}'
          memory: ${ALERTMANAGER_MEMORY_LIMIT:-512M}
        reservations:
          cpus: '${ALERTMANAGER_CPU_RESERVATION:-0.25}'
          memory: ${ALERTMANAGER_MEMORY_RESERVATION:-256M}
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 10
    restart: unless-stopped
      condition: on-failure
      delay: 5s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
    networks:
      - monitoring
    depends_on:
      - prometheus
    profiles:
      - monitoring

  # ============================================
  # Loki for Log Aggregation
  # ============================================
  loki:
    image: grafana/loki:2.9.0
    container_name: him-loki
    hostname: loki
    volumes:
      - ./monitoring/loki/loki.yml:/etc/loki/loki.yml:ro
      - loki_data:/loki
    command: -config.file=/etc/loki/loki.yml
    ports:
      - "${LOKI_PORT:-3100}:3100"
    deploy:
      resources:
        limits:
          cpus: '${LOKI_CPU_LIMIT:-1}'
          memory: ${LOKI_MEMORY_LIMIT:-1G}
        reservations:
          cpus: '${LOKI_CPU_RESERVATION:-0.5}'
          memory: ${LOKI_MEMORY_RESERVATION:-512M}
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 10
    restart: unless-stopped
      condition: on-failure
      delay: 5s
      max_attempts: 5
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
    networks:
      - monitoring
    profiles:
      - monitoring

  # ============================================
  # Fluent Bit for Log Forwarding
  # ============================================
  fluent-bit:
    image: grafana/fluent-bit-plugin-loki:2.9.0
    container_name: him-fluent-bit
    hostname: fluent-bit
    volumes:
      - ./monitoring/fluent-bit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    environment:
      LOKI_URL: http://loki:3100/loki/api/v1/push
    deploy:
      resources:
        limits:
          cpus: '${FLUENTBIT_CPU_LIMIT:-0.5}'
          memory: ${FLUENTBIT_MEMORY_LIMIT:-256M}
        reservations:
          cpus: '${FLUENTBIT_CPU_RESERVATION:-0.25}'
          memory: ${FLUENTBIT_MEMORY_RESERVATION:-128M}
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - monitoring
    depends_on:
      - loki
    profiles:
      - monitoring

  # ============================================
  # Backup Service
  # ============================================
  backup-service:
    image: ${DOCKER_REGISTRY:-docker.io}/helpinminutes/backup-service:${IMAGE_TAG:-latest}
    container_name: him-backup-service
    hostname: backup-service
    build:
      context: ../../infrastructure/backup
      dockerfile: Dockerfile
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_S3_BUCKET: ${AWS_S3_BUCKET}
      AWS_REGION: ${AWS_REGION}
      BACKUP_SCHEDULE: ${BACKUP_SCHEDULE:-0 2 * * *}
      RETENTION_DAYS: ${RETENTION_DAYS:-30}
    volumes:
      - postgres_backups:/backups
      - ./backup/scripts:/scripts:ro
    deploy:
      resources:
        limits:
          cpus: '${BACKUP_CPU_LIMIT:-0.5}'
          memory: ${BACKUP_MEMORY_LIMIT:-512M}
        reservations:
          cpus: '${BACKUP_CPU_RESERVATION:-0.25}'
          memory: ${BACKUP_MEMORY_RESERVATION:-256M}
    entrypoint: ["/bin/sh", "/scripts/entrypoint.sh"]
    networks:
      - backend
      - monitoring
    profiles:
      - backup

# ============================================
# Volumes
# ============================================
volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${POSTGRES_DATA_PATH:-./data/postgres}
  postgres_backups:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${BACKUP_PATH:-./backups}
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${REDIS_DATA_PATH:-./data/redis}
  redis_conf:
    driver: local
  rabbitmq_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${RABBITMQ_DATA_PATH:-./data/rabbitmq}
  rabbitmq_logs:
    driver: local
  minio_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${MINIO_DATA_PATH:-./data/minio}
  minio_config:
    driver: local
  prometheus_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PROMETHEUS_DATA_PATH:-./data/prometheus}
  grafana_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${GRAFANA_DATA_PATH:-./data/grafana}
  jaeger_data:
    driver: local
  alertmanager_data:
    driver: local
  loki_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${LOKI_DATA_PATH:-./data/loki}
  admin_portal_build:

# ============================================
# Networks
# ============================================
networks:
  frontend:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16
          gateway: 172.28.0.1
  backend:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.29.0.0/16
          gateway: 172.29.0.1
  storage:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.30.0.0/16
          gateway: 172.30.0.1
  monitoring:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.31.0.0/16
          gateway: 172.31.0.1

# ============================================
# Secrets (for production swarm mode)
# ============================================
secrets:
  postgres_password:
    file: ./secrets/postgres_password.txt
  redis_password:
    file: ./secrets/redis_password.txt
  rabbitmq_password:
    file: ./secrets/rabbitmq_password.txt
  jwt_secret:
    file: ./secrets/jwt_secret.txt
  razorpay_key_secret:
    file: ./secrets/razorpay_key_secret.txt
